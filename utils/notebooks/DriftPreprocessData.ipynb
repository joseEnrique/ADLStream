{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.arff as arff\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "import arff as arff1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = '../../datasets_drift/'\n",
    "arff_files = glob.glob(os.path.join(dir_path, '**/*x.arff'), recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../datasets_drift/ARGWa-F1F4x.arff',\n",
       " '../../datasets_drift/ARGWg-F1F4x.arff']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arff_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_arff(file_path, data, attributes, relation):\n",
    "    f = open(file_path, \"w\")\n",
    "    \n",
    "    f.write('@relation \\'{0}\\' \\n\\n'.format(relation))\n",
    "    \n",
    "    for attr_name, attr_type in attributes:\n",
    "        if type(attr_type) == type([]):\n",
    "            attr_type = '{{{0}}}'.format(','.join(attr_type))\n",
    "        f.write('@attribute {0} {1} \\n'.format(attr_name, attr_type))\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('@data\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    for line in data:\n",
    "        f.write(','.join([str(x) for x in line])+',\\n')    \n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 1/2 [00:35<00:35, 35.96s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 2/2 [01:12<00:00, 36.35s/it]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "for file_path in tqdm(arff_files):\n",
    "    topic = os.path.basename(file_path).replace('.arff', '')\n",
    "    data, meta = arff.loadarff(file_path)\n",
    "    dataset = pd.DataFrame(data)\n",
    "    \n",
    "    class_column = dataset.pop('class')\n",
    "    class_column = class_column.str.decode('utf-8') if type(class_column[0]) == type(b'') else class_column\n",
    "\n",
    "    numeric_columns = [column for column in dataset.columns if meta[column][0] == 'numeric']\n",
    "    nominal_columns = [column for column in dataset.columns if meta[column][0] == 'nominal']\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    dataset[numeric_columns] = scaler.fit_transform(dataset[numeric_columns])\n",
    "\n",
    "    for column in nominal_columns:\n",
    "        if type(dataset[column][0]) == type(b''):\n",
    "            dataset[column] = dataset[column].str.decode('utf-8')\n",
    "        onehotencoder = OneHotEncoder()\n",
    "        x = onehotencoder.fit_transform(dataset[[column]]).toarray()\n",
    "        new_columns = [column+'_'+str(i) for i in range(x.shape[1])]\n",
    "        for i, new_col in enumerate(new_columns):\n",
    "            dataset[new_col] = x[:,i]\n",
    "        dataset.pop(column)\n",
    "\n",
    "    dataset['class'] = class_column\n",
    "    \n",
    "    attributes = [(c, 'NUMERIC') for c in dataset.columns.values[:-1]]\n",
    "    attributes += [('class', dataset['class'].unique().astype(str).tolist())]\n",
    "    \n",
    "    data = dataset.values.tolist()\n",
    "        \n",
    "    write_arff(file_path, data, relation=topic, attributes=attributes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
